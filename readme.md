It feels related to the current AI training methods.

Current AI training methods, like reinforcement learning, only emphasize the "independent event" training framework. Within this framework, each piece of information is judged solely on its own correctness, and reinforcement learning is applied only to this aspect.

However, human high learning efficiency, besides emphasizing the correctness of each piece of information within the "independent event" framework, also emphasizes how to perform some [logically unnecessary reasoning, in terms of correctness] based on this information.
For example: How to abstract experience based on this information, and then transfer and apply this abstracted experience to other information?

But current AI training methods don't do this. Even though AI has already implemented certain mathematical concepts in other mathematical contexts, if you change a few parts of a mathematical problem while keeping the underlying mathematical concept the same, the AI fails.

When AI training breaks through the current "independent event" training framework, the AI training model can effectively reward the AI for extracting experience from past training events and using it to help with ongoing training events. At that point, AI capabilities should see another boost.